{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:04:46,053\tWARNING deprecation.py:47 -- DeprecationWarning: `ray.rllib.agents.dqn` has been deprecated. Use `ray.rllib.algorithms.[dqn|simple_q|r2d2|apex_dqn]` instead. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "import tqdm\n",
    "import matplotlib.pyplot as pp\n",
    "import numpy as np\n",
    "\n",
    "from sigma_graph.envs.figure8.action_lookup import MOVE_LOOKUP, TURN_90_LOOKUP\n",
    "from sigma_graph.envs.figure8.default_setup import OBS_TOKEN\n",
    "from sigma_graph.envs.figure8.figure8_squad_rllib import Figure8SquadRLLib\n",
    "from sigma_graph.envs.figure8.gflow_figure8_squad import GlowFigure8Squad\n",
    "#from graph_scout.envs.base import ScoutMissionStdRLLib\n",
    "import sigma_graph.envs.figure8.default_setup as default_setup\n",
    "import model  # THIS NEEDS TO BE HERE IN ORDER TO RUN __init__.py!\n",
    "import model.utils as utils\n",
    "import model.gnn_gflow \n",
    "from trajectory import Trajectory\n",
    "import losses\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import json\n",
    "\n",
    "INPUT_DIMS = 27\n",
    "OUTPUT_DIMS = 5\n",
    "NUM_EPOCHS = 100000\n",
    "TRAJECTORY_LENGTH = 20\n",
    "BATCH_SIZE = 100\n",
    "START_NODE = 25\n",
    "LEARNING_RATE = 3e-4\n",
    "WANDB = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "local_action_move = {\n",
    "    0: \"NOOP\",\n",
    "    1: \"N\",\n",
    "    2: \"S\",\n",
    "    3: \"W\",\n",
    "    4: \"E\",\n",
    "}\n",
    "\n",
    "def state_to_vec(state):\n",
    "    result = [0]*27\n",
    "    result[state-1] = 1\n",
    "    return torch.tensor(result).float()\n",
    "\n",
    "def compute_reward(state):\n",
    "    if state == 10:\n",
    "        return 2\n",
    "    if state == 2:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def convert_discrete_action_to_multidiscrete(action):\n",
    "        return [action % len(local_action_move), action // len(local_action_move)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "path_data ./GflowsForSimulation/sigma_graph/data/parsed/\n",
      "/Users/ryanmarr/Documents/CognArch/GflowsForSimulation\n"
     ]
    }
   ],
   "source": [
    "# Investigate loss rewar mirror\n",
    "# Try real reward\n",
    "# Make code cleaner \n",
    "# visualize flows \n",
    "\n",
    "if WANDB:\n",
    "    wandb.init(\n",
    "        project=\"graph-training-simulation\",\n",
    "        config={\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"epocs\": NUM_EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE\n",
    "        }\n",
    "    )\n",
    "\n",
    "config = {\n",
    "    \"custom_model\": \"attn_fcn\",\n",
    "    \"reward\": \"toy\",\n",
    "    \"custom_model_config\": {\n",
    "        \"nred\": 1,\n",
    "        \"nblue\": 1,\n",
    "        \"aggregation_fn\": \"agent_node\",\n",
    "        \"hidden_size\": 15,\n",
    "        \"is_hybrid\": False,\n",
    "        \"conv_type\": \"gcn\",\n",
    "        \"layernorm\": False,\n",
    "        \"graph_obs_token\": {\"embed_opt\": False, \"embed_dir\": True},\n",
    "    },\n",
    "    \"env_config\": {\n",
    "        \"env_path\": \".\",\n",
    "        \"act_masked\": True,\n",
    "        \"init_red\": None,\n",
    "        \"init_blue\": None,\n",
    "        \"init_health_red\": 20,\n",
    "        \"init_health_blue\": 20,\n",
    "        \"obs_embed\": False,\n",
    "        \"obs_dir\": False,\n",
    "        \"obs_team\": True,\n",
    "        \"obs_sight\": False,\n",
    "        \"log_on\": True,\n",
    "        \"log_path\": \"logs/temp/\",\n",
    "        \"fixed_start\": -1,\n",
    "        \"penalty_stay\": 0,\n",
    "        \"threshold_damage_2_blue\": 2,\n",
    "        \"threshold_damage_2_red\": 5,\n",
    "    },\n",
    "}\n",
    "LEARNING_RATE = 3e-4\n",
    "gflowfigure8 = GlowFigure8Squad(sampler_config=config)\n",
    "# sampler_fcn -> sampler\n",
    "# TODO: this is bad revisit and come up with something more concise\n",
    "\n",
    "optimizer = optim.AdamW(gflowfigure8.sampler.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%| | 67/100000 [00:25<10:26:27,  2.66\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m total_reward \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(TRAJECTORY_LENGTH):\n\u001b[0;32m---> 21\u001b[0m   step \u001b[39m=\u001b[39m gflowfigure8\u001b[39m.\u001b[39;49mstep(TEMP_AGENT_INDEX)  \n\u001b[1;32m     22\u001b[0m   total_P_F \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m step[\u001b[39m'\u001b[39m\u001b[39mforward_prob\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     23\u001b[0m   total_P_B \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m step[\u001b[39m'\u001b[39m\u001b[39mbackward_prob\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/CognArch/GflowsForSimulation/sigma_graph/envs/figure8/gflow_figure8_squad.py:182\u001b[0m, in \u001b[0;36mGlowFigure8Squad.step\u001b[0;34m(self, a_id)\u001b[0m\n\u001b[1;32m    179\u001b[0m R_engage_B, B_engage_R, R_overlay \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update()\n\u001b[1;32m    181\u001b[0m \u001b[39m# prev_obs = [self.states[a_id],]\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m probs_forward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msampler\u001b[39m.\u001b[39;49mforward(torch\u001b[39m.\u001b[39;49mtensor(np\u001b[39m.\u001b[39;49marray([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstates[a_id],], dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mint8), device\u001b[39m=\u001b[39;49mdevice),\n\u001b[1;32m    183\u001b[0m                                       reward_nodes\u001b[39m=\u001b[39;49mreward_node)\n\u001b[1;32m    185\u001b[0m \u001b[39m# TODO fix this\u001b[39;00m\n\u001b[1;32m    186\u001b[0m cat \u001b[39m=\u001b[39m Categorical(logits\u001b[39m=\u001b[39mprobs_forward)\n",
      "File \u001b[0;32m~/Documents/CognArch/GflowsForSimulation/model/samplers.py:393\u001b[0m, in \u001b[0;36mSamplerAttnFCN.forward\u001b[0;34m(self, obs, reward_nodes)\u001b[0m\n\u001b[1;32m    391\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madj_matrix)\n\u001b[1;32m    392\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(x)\n\u001b[0;32m--> 393\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madj_matrix)\n\u001b[1;32m    395\u001b[0m bool_obs \u001b[39m=\u001b[39m obs\u001b[39m.\u001b[39mbool()[\u001b[39m0\u001b[39m]\n\u001b[1;32m    396\u001b[0m cur_node \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mget_loc(bool_obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_size) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/CognArch/.cogn_arch/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/CognArch/.cogn_arch/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CognArch/GflowsForSimulation/model/gat.py:50\u001b[0m, in \u001b[0;36mGraphAttentionLayer.forward\u001b[0;34m(self, h, adj_mat)\u001b[0m\n\u001b[1;32m     47\u001b[0m a \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax(e)\n\u001b[1;32m     48\u001b[0m a \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(a)\n\u001b[0;32m---> 50\u001b[0m attn_res \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49meinsum(\u001b[39m'\u001b[39;49m\u001b[39mijh,jhf->ihf\u001b[39;49m\u001b[39m'\u001b[39;49m, a, g)\n\u001b[1;32m     52\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_concat:\n\u001b[1;32m     53\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_res\u001b[39m.\u001b[39mreshape(n_nodes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_heads \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_hidden)\n",
      "File \u001b[0;32m~/Documents/CognArch/.cogn_arch/lib/python3.10/site-packages/torch/functional.py:377\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[39mreturn\u001b[39;00m einsum(equation, \u001b[39m*\u001b[39m_operands)\n\u001b[1;32m    374\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(operands) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m opt_einsum\u001b[39m.\u001b[39menabled:\n\u001b[1;32m    375\u001b[0m     \u001b[39m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[39m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49meinsum(equation, operands)  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    379\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m opt_einsum\u001b[39m.\u001b[39mis_available():\n",
      "File \u001b[0;32m~/Documents/CognArch/.cogn_arch/lib/python3.10/site-packages/torch/fx/traceback.py:68\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m [current_meta\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstack_trace\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m     66\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[39m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mreturn\u001b[39;00m traceback\u001b[39m.\u001b[39mformat_list(traceback\u001b[39m.\u001b[39;49mextract_stack()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[0;32m--> 227\u001b[0m stack \u001b[39m=\u001b[39m StackSummary\u001b[39m.\u001b[39;49mextract(walk_stack(f), limit\u001b[39m=\u001b[39;49mlimit)\n\u001b[1;32m    228\u001b[0m stack\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    229\u001b[0m \u001b[39mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/traceback.py:379\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    376\u001b[0m     result\u001b[39m.\u001b[39mappend(FrameSummary(\n\u001b[1;32m    377\u001b[0m         filename, lineno, name, lookup_line\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39mf_locals))\n\u001b[1;32m    378\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m fnames:\n\u001b[0;32m--> 379\u001b[0m     linecache\u001b[39m.\u001b[39;49mcheckcache(filename)\n\u001b[1;32m    380\u001b[0m \u001b[39m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[39mcontinue\u001b[39;00m   \u001b[39m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     stat \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(fullname)\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     cache\u001b[39m.\u001b[39mpop(filename, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Using sigma code fully\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "minibatch_loss = 0\n",
    "minibatch_reward = 0\n",
    "minibatch_z = 0\n",
    "minibatch_pf = 0\n",
    "minibatch_pb = 0\n",
    "\n",
    "for episode in tqdm.tqdm(range(NUM_EPOCHS), ncols=40):\n",
    "  \n",
    "  TEMP_AGENT_INDEX = 0\n",
    "  gflowfigure8._reset_agents()\n",
    "\n",
    "  total_P_F = 0\n",
    "  total_P_B = 0\n",
    "  total_reward = 0\n",
    "  for t in range(TRAJECTORY_LENGTH):\n",
    "\n",
    "    step = gflowfigure8.step(TEMP_AGENT_INDEX)  \n",
    "    total_P_F += step['forward_prob']\n",
    "    total_P_B += step['backward_prob']\n",
    "    #total_reward += torch.tensor(gflowfigure8._step_reward_test())\n",
    "    total_reward += step['step_reward']\n",
    "\n",
    "  logZ = gflowfigure8.sampler.logZ\n",
    " \n",
    "  clipped_reward = torch.log(torch.tensor(total_reward)).clip(-20)\n",
    "  loss = (logZ + total_P_F - clipped_reward - total_P_B).pow(2)\n",
    "  \n",
    "  minibatch_loss += loss\n",
    "  minibatch_reward += clipped_reward\n",
    "  minibatch_z += logZ\n",
    "  minibatch_pf += total_P_F\n",
    "  minibatch_pb += total_P_B\n",
    "\n",
    "  if (episode + 1) % BATCH_SIZE == 0:\n",
    "    if WANDB:\n",
    "      wandb.log({\n",
    "          \"loss\": minibatch_loss/BATCH_SIZE, \n",
    "          \"reward\":  minibatch_reward/BATCH_SIZE,\n",
    "          \"pf\": minibatch_pf/BATCH_SIZE,\n",
    "          \"pb\": minibatch_pb/BATCH_SIZE,\n",
    "          \"Z\": minibatch_z/BATCH_SIZE\n",
    "        })\n",
    "      # for name, param in sampler.named_parameters():\n",
    "      #     wandb.log({f\"{name}_mean\": param.data.mean().item(), f\"{name}_std\": param.data.std().item()})\n",
    "    \n",
    "    minibatch_loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    minibatch_loss = 0\n",
    "    minibatch_reward = 0\n",
    "    minibatch_z = 0\n",
    "    minibatch_pf = 0\n",
    "    minibatch_pb = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: there has to be a better way to do this\n",
    "def norm_dict(unnorm):\n",
    "    min_val = 9999999\n",
    "    for key in unnorm:\n",
    "        min_val = min(unnorm[key], min_val)\n",
    "    for key in unnorm:\n",
    "        unnorm[key] = unnorm[key] + (min(min_val, 0) * -1)\n",
    "    sum = 0\n",
    "    for key in unnorm:\n",
    "        sum += unnorm[key]\n",
    "    for key in unnorm:\n",
    "        unnorm[key] /= sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gflowfigure8._reset_agents()\n",
    "state_dirs = {}\n",
    "for node in range(27):\n",
    "    states = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "    states[0][node] = 1\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    state = torch.tensor(np.array([states[0],], dtype=np.int8)).to(device)\n",
    "    probs = gflowfigure8.sampler.forward(state)\n",
    "    # (forward_prob, action) = gflowfigure8.probs_to_action(probs)\n",
    "    total_probs = {}\n",
    "    total_probs[\"NOOP\"] = (probs[0]+probs[5]+probs[10]).tolist()\n",
    "    total_probs[\"N\"] = (probs[1]+probs[6]+probs[11]).tolist()\n",
    "    total_probs[\"S\"] = (probs[2]+probs[7]+probs[12]).tolist()\n",
    "    total_probs[\"W\"] = (probs[3]+probs[8]+probs[13]).tolist()\n",
    "    total_probs[\"E\"] = (probs[4]+probs[9]+probs[14]).tolist()\n",
    "    \n",
    "    norm_dict(total_probs)\n",
    "\n",
    "    state_dirs[node] = total_probs\n",
    "\n",
    "json_data = json.dumps(state_dirs, indent=2)\n",
    "with open('logs/temp/flows.json', 'w') as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trajectory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trajectory \u001b[39m=\u001b[39m Trajectory()\n\u001b[1;32m      2\u001b[0m gflowfigure8\u001b[39m.\u001b[39m_reset_agents()\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m20\u001b[39m):   \n",
      "\u001b[0;31mNameError\u001b[0m: name 'Trajectory' is not defined"
     ]
    }
   ],
   "source": [
    "trajectory = Trajectory()\n",
    "gflowfigure8._reset_agents()\n",
    "for _ in range(20):   \n",
    "    for a_id in range(config['custom_model_config']['nred']):\n",
    "        step = gflowfigure8.step(a_id)\n",
    "        trajectory.add_step(\n",
    "            forward_prob=step['forward_prob'],\n",
    "            backward_prob=step['backward_prob'],\n",
    "            # flow=step['flow'],\n",
    "            # action=step['action'],\n",
    "            reward=step['step_reward'],\n",
    "            # node=step['node']\n",
    "        )\n",
    "        print(step['node'])\n",
    "        #print(step['action'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".cogn_arch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
