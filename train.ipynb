{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 19:18:49,065\tWARNING deprecation.py:47 -- DeprecationWarning: `ray.rllib.agents.dqn` has been deprecated. Use `ray.rllib.algorithms.[dqn|simple_q|r2d2|apex_dqn]` instead. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "# general\n",
    "import argparse\n",
    "import pickle\n",
    "import torch\n",
    "import time\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import wandb\n",
    "#from ray.rllib.agents import ppo, dqn, pg, a3c, impala\n",
    "from tqdm import tnrange\n",
    "\n",
    "# our code\n",
    "from sigma_graph.envs.figure8.action_lookup import MOVE_LOOKUP, TURN_90_LOOKUP\n",
    "from sigma_graph.envs.figure8.default_setup import OBS_TOKEN\n",
    "from sigma_graph.envs.figure8.figure8_squad_rllib import Figure8SquadRLLib\n",
    "from sigma_graph.envs.figure8.gflow_figure8_squad import GlowFigure8Squad\n",
    "#from graph_scout.envs.base import ScoutMissionStdRLLib\n",
    "import sigma_graph.envs.figure8.default_setup as default_setup\n",
    "import model  # THIS NEEDS TO BE HERE IN ORDER TO RUN __init__.py!\n",
    "import model.utils as utils\n",
    "import model.gnn_gflow \n",
    "from trajectory import Trajectory\n",
    "import losses\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB = True\n",
    "SEED = 0\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 3000\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mr-marr747\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rmarr/Documents/GflowsForSimulation_env/GflowsForSimulation/wandb/run-20240202_191850-mx1nx1bu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/r-marr747/graph-training-simulation/runs/mx1nx1bu' target=\"_blank\">apricot-field-123</a></strong> to <a href='https://wandb.ai/r-marr747/graph-training-simulation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/r-marr747/graph-training-simulation' target=\"_blank\">https://wandb.ai/r-marr747/graph-training-simulation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/r-marr747/graph-training-simulation/runs/mx1nx1bu' target=\"_blank\">https://wandb.ai/r-marr747/graph-training-simulation/runs/mx1nx1bu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if WANDB:\n",
    "    wandb.login()\n",
    "    wandb.init(\n",
    "        project=\"graph-training-simulation\",\n",
    "        config={\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"seed\": SEED\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"custom_model\": \"graph_transformer_policy\",\n",
    "    \"custom_model_config\": {\n",
    "        \"nred\": 1,\n",
    "        \"nblue\": 1,\n",
    "        \"aggregation_fn\": \"agent_node\",\n",
    "        \"hidden_size\": 10,\n",
    "        \"is_hybrid\": False,\n",
    "        \"conv_type\": \"gcn\",\n",
    "        \"layernorm\": False,\n",
    "        \"graph_obs_token\": {\"embed_opt\": False, \"embed_dir\": True},\n",
    "    },\n",
    "    \"env_config\": {\n",
    "        \"env_path\": \".\",\n",
    "        \"act_masked\": True,\n",
    "        \"init_red\": None,\n",
    "        \"init_blue\": None,\n",
    "        \"init_health_red\": 20,\n",
    "        \"init_health_blue\": 20,\n",
    "        \"obs_embed\": False,\n",
    "        \"obs_dir\": False,\n",
    "        \"obs_team\": True,\n",
    "        \"obs_sight\": False,\n",
    "        \"log_on\": False,\n",
    "        \"log_path\": \"logs/temp/\",\n",
    "        \"fixed_start\": -1,\n",
    "        \"penalty_stay\": 0,\n",
    "        \"threshold_damage_2_blue\": 2,\n",
    "        \"threshold_damage_2_red\": 5,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa8624df3b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "path_data ./GflowsForSimulation/sigma_graph/data/parsed/\n",
      "/home/rmarr/Documents/GflowsForSimulation_env/GflowsForSimulation\n"
     ]
    }
   ],
   "source": [
    "gflowfigure8 = GlowFigure8Squad(sampler_config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "gflowfigure8 = GlowFigure8Squad(sampler_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(gflowfigure8.sampler_fcn.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "batch_loss = 0\n",
    "batch_num = 0\n",
    "batch_reward = 0\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    trajectory = Trajectory()\n",
    "    gflowfigure8._reset_agents()\n",
    "    for _ in range(20):   \n",
    "        for a_id in range(config['custom_model_config']['nred']):\n",
    "            step = gflowfigure8.step(a_id)\n",
    "            trajectory.add_step(\n",
    "                forward_prob=step['forward_prob'],\n",
    "                backward_prob=step['backward_prob'],\n",
    "                # flow=step['flow'],\n",
    "                # action=step['action'],\n",
    "                reward=step['step_reward'],\n",
    "                # node=step['node']\n",
    "            )\n",
    "    \n",
    "    episode_loss = losses.Losses.trajectory_balance(trajectory)\n",
    "    episode_reward = trajectory.rewards\n",
    "\n",
    "    batch_num = batch_num + 1\n",
    "    batch_loss += episode_loss\n",
    "    batch_reward += episode_reward\n",
    "\n",
    "    if batch_num % BATCH_SIZE == 0:\n",
    "        if WANDB:\n",
    "            wandb.log({\"loss\": batch_loss/BATCH_SIZE, \"reward\":  batch_reward/BATCH_SIZE})\n",
    "            batch_loss = 0\n",
    "            batch_reward = 0\n",
    "            for name, param in gflowfigure8.sampler_fcn.named_parameters():\n",
    "                wandb.log({f\"{name}_mean\": param.data.mean().item(), f\"{name}_std\": param.data.std().item()})\n",
    "\n",
    "    episode_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'NOOP': 0.17820949651079954, 'N': 0.19639840144099877, 'S': 0.20381606319986284, 'W': 0.2254008692661287, 'E': 0.1961751695822102}, 1: {'NOOP': 0.18217598909235266, 'N': 0.19812147970705368, 'S': 0.19669236652488165, 'W': 0.21663757582996856, 'E': 0.2063725888457435}, 2: {'NOOP': 0.18004291409355228, 'N': 0.19487807413016764, 'S': 0.221700904809441, 'W': 0.19689705364023707, 'E': 0.20648105332660185}, 3: {'NOOP': 0.18169170924137149, 'N': 0.18619650300562068, 'S': 0.22019112569198818, 'W': 0.2079897318416776, 'E': 0.20393093021934208}, 4: {'NOOP': 0.18428485523093124, 'N': 0.1944376562795975, 'S': 0.20081464503836322, 'W': 0.22708909770667018, 'E': 0.19337374574443794}, 5: {'NOOP': 0.19413872073804495, 'N': 0.18301615324898782, 'S': 0.20584071761857042, 'W': 0.23640976764821833, 'E': 0.18059464074617837}, 6: {'NOOP': 0.1858327918118302, 'N': 0.16176891499626472, 'S': 0.22773962216945004, 'W': 0.25647981870644243, 'E': 0.16817885231601246}, 7: {'NOOP': 0.18215174715508717, 'N': 0.17804581583805892, 'S': 0.22525109082090763, 'W': 0.20644231724188705, 'E': 0.20810902894405925}, 8: {'NOOP': 0.1739629861370454, 'N': 0.18592307169281802, 'S': 0.20470431556815064, 'W': 0.27301190699791084, 'E': 0.1623977196040751}, 9: {'NOOP': 0.2114899367995085, 'N': 0.145234831854486, 'S': 0.22719885438719678, 'W': 0.23128179069500737, 'E': 0.18479458626380124}, 10: {'NOOP': 0.19784257124705262, 'N': 0.16403310110009198, 'S': 0.263695653153089, 'W': 0.18159138971307814, 'E': 0.19283728478668832}, 11: {'NOOP': 0.1749451678071332, 'N': 0.19080741847148905, 'S': 0.19300748625703393, 'W': 0.24857173603480437, 'E': 0.19266819142953948}, 12: {'NOOP': 0.17105424500452612, 'N': 0.19410668860280533, 'S': 0.19336194827508582, 'W': 0.24881205753497454, 'E': 0.19266506058260816}, 13: {'NOOP': 0.1885439069915387, 'N': 0.19974794597690343, 'S': 0.2158274836239907, 'W': 0.19581349777752594, 'E': 0.20006716563004123}, 14: {'NOOP': 0.1844347379479535, 'N': 0.19361726718050606, 'S': 0.24086560900889037, 'W': 0.18250075756866313, 'E': 0.1985816282939869}, 15: {'NOOP': 0.18585648836397112, 'N': 0.1897475251675541, 'S': 0.19002945475884925, 'W': 0.2304570172512372, 'E': 0.2039095144583884}, 16: {'NOOP': 0.1853407031105846, 'N': 0.20267183205123387, 'S': 0.19120535097713492, 'W': 0.22411889638794236, 'E': 0.19666321747310422}, 17: {'NOOP': 0.17139186302490622, 'N': 0.18586585450257176, 'S': 0.2000025919962793, 'W': 0.26128116938323015, 'E': 0.18145852109301264}, 18: {'NOOP': 0.16215426397671584, 'N': 0.2061730882136259, 'S': 0.21467077122904696, 'W': 0.2019939119496926, 'E': 0.2150079646309187}, 19: {'NOOP': 0.1730463475245792, 'N': 0.21637338199026648, 'S': 0.2020062938834794, 'W': 0.20573889932336253, 'E': 0.20283507727831235}, 20: {'NOOP': 0.17401278368846862, 'N': 0.20915860543201334, 'S': 0.19767281977061846, 'W': 0.2183545197015972, 'E': 0.20080127140730247}, 21: {'NOOP': 0.1890525758686234, 'N': 0.19712830722618124, 'S': 0.1931244205422654, 'W': 0.22044529324404225, 'E': 0.20024940311888775}, 22: {'NOOP': 0.19265182387737956, 'N': 0.19067422470179013, 'S': 0.20989023621287656, 'W': 0.2012235265252518, 'E': 0.2055601886827021}, 23: {'NOOP': 0.1842759781301731, 'N': 0.19721168166986108, 'S': 0.1876017819765185, 'W': 0.22568943938760525, 'E': 0.20522111883584204}, 24: {'NOOP': 0.1883784820247994, 'N': 0.18817623967260927, 'S': 0.19631861123843583, 'W': 0.22926222705859478, 'E': 0.1978644400055606}, 25: {'NOOP': 0.18671206258041212, 'N': 0.2062121111305363, 'S': 0.1895246645987934, 'W': 0.20868756649813575, 'E': 0.20886359519212244}, 26: {'NOOP': 0.17861992896247958, 'N': 0.2061817953941546, 'S': 0.18747431893494357, 'W': 0.2147285044719, 'E': 0.21299545223652233}}\n"
     ]
    }
   ],
   "source": [
    "gflowfigure8._reset_agents()\n",
    "state_dirs = {}\n",
    "for node in range(27):\n",
    "    states = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "    states[0][node] = 1\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    state = torch.tensor(np.array([states[0],], dtype=np.int8)).to(device)\n",
    "    probs = gflowfigure8.sampler_fcn.forward(state)\n",
    "    # (forward_prob, action) = gflowfigure8.probs_to_action(probs)\n",
    "    total_probs = {}\n",
    "    total_probs[\"NOOP\"] = (probs[0]+probs[5]+probs[10]).tolist()\n",
    "    total_probs[\"N\"] = (probs[1]+probs[6]+probs[11]).tolist()\n",
    "    total_probs[\"S\"] = (probs[2]+probs[7]+probs[12]).tolist()\n",
    "    total_probs[\"W\"] = (probs[3]+probs[8]+probs[13]).tolist()\n",
    "    total_probs[\"E\"] = (probs[4]+probs[9]+probs[14]).tolist()\n",
    "    \n",
    "    state_dirs[node] = total_probs\n",
    "print(state_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = Trajectory()\n",
    "gflowfigure8._reset_agents()\n",
    "for _ in range(20):   \n",
    "    for a_id in range(config['custom_model_config']['nred']):\n",
    "        step = gflowfigure8.step(a_id)\n",
    "        trajectory.add_step(\n",
    "            forward_prob=step['forward_prob'],\n",
    "            backward_prob=step['backward_prob'],\n",
    "            # flow=step['flow'],\n",
    "            # action=step['action'],\n",
    "            reward=step['step_reward'],\n",
    "            # node=step['node']\n",
    "        )\n",
    "    print(step['node'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GflowsForSimulation_venv_real",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
