{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 13:41:15,541\tWARNING deprecation.py:47 -- DeprecationWarning: `ray.rllib.agents.dqn` has been deprecated. Use `ray.rllib.algorithms.[dqn|simple_q|r2d2|apex_dqn]` instead. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as pp\n",
    "import numpy as np\n",
    "from ipywidgets import interact, IntSlider, fixed\n",
    "\n",
    "from sigma_graph.envs.figure8.action_lookup import MOVE_LOOKUP, TURN_90_LOOKUP\n",
    "from sigma_graph.envs.figure8.default_setup import OBS_TOKEN\n",
    "from sigma_graph.envs.figure8.figure8_squad_rllib import Figure8SquadRLLib\n",
    "from sigma_graph.envs.figure8.gflow_figure8_squad import GlowFigure8Squad\n",
    "#from graph_scout.envs.base import ScoutMissionStdRLLib\n",
    "import sigma_graph.envs.figure8.default_setup as default_setup\n",
    "from sigma_graph.data.file_manager import check_dir, find_file_in_dir, load_graph_files\n",
    "import model  # THIS NEEDS TO BE HERE IN ORDER TO RUN __init__.py!\n",
    "import model.utils as utils\n",
    "import model.gnn_gflow \n",
    "from trajectory import Trajectory\n",
    "import losses\n",
    "\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import json\n",
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gflowfigure8 = torch.load('models/gnn_10_steps.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlowFigure8Squad' object has no attribute 'sampler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray([states[\u001b[38;5;241m0\u001b[39m],], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint8))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 21\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[43mgflowfigure8\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[38;5;241m.\u001b[39mforward(state, [\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# (forward_prob, action) = gflowfigure8.probs_to_action(probs)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m total_probs \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlowFigure8Squad' object has no attribute 'sampler'"
     ]
    }
   ],
   "source": [
    "# TODO: there has to be a better way to do this\n",
    "def norm_dict(unnorm):\n",
    "    min_val = 9999999\n",
    "    for key in unnorm:\n",
    "        min_val = min(unnorm[key], min_val)\n",
    "    for key in unnorm:\n",
    "        unnorm[key] = unnorm[key] + (min(min_val, 0) * -1)\n",
    "    sum = 0\n",
    "    for key in unnorm:\n",
    "        sum += unnorm[key]\n",
    "    for key in unnorm:\n",
    "        unnorm[key] /= sum\n",
    "        \n",
    "gflowfigure8._reset_agents()\n",
    "state_dirs = {}\n",
    "for node in range(27):\n",
    "    states = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "    states[0][node] = 1\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    state = torch.tensor(np.array([states[0],], dtype=np.int8)).to(device)\n",
    "    probs = gflowfigure8.sampler.forward(state, [1])\n",
    "    # (forward_prob, action) = gflowfigure8.probs_to_action(probs)\n",
    "    total_probs = {}\n",
    "    total_probs[\"NOOP\"] = (probs[0]+probs[5]+probs[10]).tolist()\n",
    "    total_probs[\"N\"] = (probs[1]+probs[6]+probs[11]).tolist()\n",
    "    total_probs[\"S\"] = (probs[2]+probs[7]+probs[12]).tolist()\n",
    "    total_probs[\"W\"] = (probs[3]+probs[8]+probs[13]).tolist()\n",
    "    total_probs[\"E\"] = (probs[4]+probs[9]+probs[14]).tolist()\n",
    "    #norm_dict(total_probs)\n",
    "\n",
    "    state_dirs[node] = total_probs\n",
    "\n",
    "print(state_dirs)\n",
    "flows = state_dirs\n",
    "print(f'flows {flows}')\n",
    "map_info, _ = load_graph_files(map_lookup=\"S\")\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.patch.set_alpha(0.)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "col_map = [\"gold\"] * len(map_info.n_info)\n",
    "\n",
    "nx.draw_networkx(map_info.g_acs, map_info.n_info, node_color=col_map, edge_color=\"blue\", arrows=True)\n",
    "\n",
    "# max_x = max(pos[0] for pos in map_info.n_info.values())\n",
    "# max_y = max(pos[1] for pos in map_info.n_info.values())\n",
    "# scale_factor = max(max_x, max_y) / 2000\n",
    "# op_to_dir = {\n",
    "#     'N': (0, 1), \n",
    "#     'S': (0, -1), \n",
    "#     'W': (-1, 0),\n",
    "#     'E': (1, 0)\n",
    "# }\n",
    "# for node in map_info.g_acs.nodes:\n",
    "#     pos = map_info.n_info[node]\n",
    "#     x, y = pos\n",
    "#     dir_flows = flows[node-1]\n",
    "\n",
    "#     color_vals = np.linspace(0, 1.75, 100)\n",
    "#     colors = [(color, 0, 0, 0) for color in color_vals]\n",
    "\n",
    "#     for op in ['N', 'S', 'W', 'E']:\n",
    "#         flow = int((dir_flows[op]) * 99)\n",
    "#         dx, dy = op_to_dir[op]\n",
    "#         plt.arrow(x, y, dx*scale_factor, dy*scale_factor, color=colors[flow], alpha=1, width=0.1, head_width=1)\n",
    "\n",
    "#     circle_radius = 1.00 \n",
    "#     circle_center_x = x + circle_radius  \n",
    "#     circle_center_y = y + circle_radius \n",
    "\n",
    "#     flow = int((dir_flows['NOOP']) * 99)\n",
    "\n",
    "#     circle = plt.Circle((circle_center_x, circle_center_y), circle_radius, color=colors[flow], alpha=0.8, fill=False, linewidth=2)\n",
    "\n",
    "#     plt.gca().add_patch(circle)\n",
    "\n",
    "\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlowFigure8Squad' object has no attribute 'total_reward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m total_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m34\u001b[39m):   \n\u001b[0;32m----> 7\u001b[0m     step \u001b[38;5;241m=\u001b[39m \u001b[43mgflowfigure8\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_fcn_coordinate_time\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     red_path\u001b[38;5;241m.\u001b[39mappend(step[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred_node\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m     blue_path\u001b[38;5;241m.\u001b[39mappend(step[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue_node\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/GflowsForSimulation_env/GflowsForSimulation/sigma_graph/envs/figure8/gflow_figure8_squad.py:285\u001b[0m, in \u001b[0;36mGlowFigure8Squad.step_fcn_coordinate_time\u001b[0;34m(self, a_id)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    284\u001b[0m step_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(red_node \u001b[38;5;241m==\u001b[39m blue_node) \u001b[38;5;66;03m#int(R_overlay[0])\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m step_reward\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m#step_reward = self._step_rewards_aggresssive(action_penalty_red, R_engage_B, B_engage_R, R_overlay)[0] \u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ({\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward_prob\u001b[39m\u001b[38;5;124m'\u001b[39m: forward_prob,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue_node\u001b[39m\u001b[38;5;124m'\u001b[39m: blue_node\n\u001b[1;32m    297\u001b[0m })\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlowFigure8Squad' object has no attribute 'total_reward'"
     ]
    }
   ],
   "source": [
    "gflowfigure8.reset()\n",
    "red_path = []\n",
    "blue_path = []\n",
    "step_rewards = []\n",
    "total_reward = 0\n",
    "gflowfigure8.reset_state()\n",
    "for r in range(34):   \n",
    "    step = gflowfigure8.step_fcn_coordinate_time(0)\n",
    "    red_path.append(step['red_node'])\n",
    "    blue_path.append(step['blue_node'])\n",
    "    step_rewards.append(step['step_reward'])\n",
    "    total_reward += step['step_reward']\n",
    "\n",
    "print(f'step_rewards {total_reward}')\n",
    "clipped_reward = torch.log(torch.tensor(total_reward)).clip(-20)\n",
    "print(f'clipped_reward {clipped_reward}')\n",
    "\n",
    "map_info, _ = load_graph_files(map_lookup=\"S\")\n",
    "col_map = [\"gold\"] * len(map_info.n_info)\n",
    "\n",
    "def display_graph(index):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cur_col_map = col_map[:]\n",
    "    cur_col_map[red_path[index]-1] = \"red\"\n",
    "    cur_col_map[blue_path[index]-1] = \"blue\"\n",
    "    nx.draw_networkx(map_info.g_acs, pos=map_info.n_info, node_color=cur_col_map, edge_color=\"blue\", arrows=True, ax=ax)\n",
    "    ax.set_title(f\"step rewards {step_rewards[index]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Create an interactive widget to display different graphs\n",
    "slider = IntSlider(min=0, max=33, step=1, value=0, description='Graph Index')\n",
    "interact(display_graph, index=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlowFigure8Squad' object has no attribute 'reset_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m step_rewards \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m total_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mgflowfigure8\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_state\u001b[49m()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m34\u001b[39m):   \n\u001b[1;32m     10\u001b[0m     step \u001b[38;5;241m=\u001b[39m gflowfigure8\u001b[38;5;241m.\u001b[39mstep_fcn_coordinate_time(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlowFigure8Squad' object has no attribute 'reset_state'"
     ]
    }
   ],
   "source": [
    "# visualize fcn coordinate time\n",
    "\n",
    "gflowfigure8.reset()\n",
    "red_path = []\n",
    "blue_path = []\n",
    "step_rewards = []\n",
    "total_reward = 0\n",
    "gflowfigure8.reset_state()\n",
    "for r in range(34):   \n",
    "    step = gflowfigure8.step_fcn_coordinate_time(0)\n",
    "    red_path.append(step['red_node'])\n",
    "    blue_path.append(step['blue_node'])\n",
    "    step_rewards.append(step['step_reward'])\n",
    "    total_reward += step['step_reward']\n",
    "\n",
    "print(f'step_rewards {total_reward}')\n",
    "clipped_reward = torch.log(torch.tensor(total_reward)).clip(-20)\n",
    "print(f'clipped_reward {clipped_reward}')\n",
    "\n",
    "map_info, _ = load_graph_files(map_lookup=\"S\")\n",
    "col_map = [\"gold\"] * len(map_info.n_info)\n",
    "\n",
    "def display_graph(index):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cur_col_map = col_map[:]\n",
    "    cur_col_map[red_path[index]-1] = \"red\"\n",
    "    cur_col_map[blue_path[index]-1] = \"blue\"\n",
    "    nx.draw_networkx(map_info.g_acs, pos=map_info.n_info, node_color=cur_col_map, edge_color=\"blue\", arrows=True, ax=ax)\n",
    "    ax.set_title(f\"step rewards {step_rewards[index]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Create an interactive widget to display different graphs\n",
    "slider = IntSlider(min=0, max=33, step=1, value=0, description='Graph Index')\n",
    "interact(display_graph, index=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_rewards 2\n",
      "clipped_reward 0.6931471824645996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a67e3f762d441a0a56600f593e3fa98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Graph Index', max=9), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.display_graph(index)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize gat coordinate time\n",
    "\n",
    "red_path = []\n",
    "blue_path = []\n",
    "step_rewards = []\n",
    "total_reward = 0\n",
    "gflowfigure8.reset_state_gat_coordinate_time()\n",
    "for r in range(10):   \n",
    "    step = gflowfigure8.step_gat_coordinate_time_deterministic(0)\n",
    "    red_path.append(step['red_node'])\n",
    "    blue_path.append(step['blue_node'])\n",
    "    step_rewards.append(step['step_reward'])\n",
    "    total_reward += step['step_reward']\n",
    "\n",
    "print(f'step_rewards {total_reward}')\n",
    "clipped_reward = torch.log(torch.tensor(total_reward)).clip(-20)\n",
    "print(f'clipped_reward {clipped_reward}')\n",
    "\n",
    "map_info, _ = load_graph_files(map_lookup=\"S\")\n",
    "col_map = [\"gold\"] * len(map_info.n_info)\n",
    "\n",
    "def display_graph(index):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cur_col_map = col_map[:]\n",
    "    cur_col_map[red_path[index]-1] = \"red\"\n",
    "    cur_col_map[blue_path[index]-1] = \"blue\"\n",
    "    nx.draw_networkx(map_info.g_acs, pos=map_info.n_info, node_color=cur_col_map, edge_color=\"blue\", arrows=True, ax=ax)\n",
    "    ax.set_title(f\"step rewards {step_rewards[index]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Create an interactive widget to display different graphs\n",
    "slider = IntSlider(min=0, max=9, step=1, value=0, description='Graph Index')\n",
    "interact(display_graph, index=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_path = [21, 27, 20, 14, 8, 7, 7, 8, 14, 20, 20, 20, 20, 20, 20, 20, 14, 8, 7, 7]\n",
    "blue_path = [21, 27, 20, 14, 8,  7,  9,  10, 11, 16, 17, 22, 21, 27, 20, 26, 19, 25, 18, 12]\n",
    "\n",
    "map_info, _ = load_graph_files(map_lookup=\"S\")\n",
    "col_map = [\"gold\"] * len(map_info.n_info)\n",
    "\n",
    "def display_graph(index):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cur_col_map = col_map[:]\n",
    "    cur_col_map[red_path[index]-1] = \"red\"\n",
    "    cur_col_map[blue_path[index]-1] = \"blue\"\n",
    "    nx.draw_networkx(map_info.g_acs, pos=map_info.n_info, node_color=cur_col_map, edge_color=\"blue\", arrows=True, ax=ax)\n",
    "    ax.set_title(f\"step rewards {step_rewards[index]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Create an interactive widget to display different graphs\n",
    "slider = IntSlider(min=0, max=9, step=1, value=0, description='Graph Index')\n",
    "interact(display_graph, index=slider)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
